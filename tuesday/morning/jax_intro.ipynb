{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57848c7b",
   "metadata": {},
   "source": [
    "# An Introduction to JAX\n",
    "\n",
    "----\n",
    "\n",
    "#### Chase Coleman and John Stachurski\n",
    "\n",
    "#### Prepared for the QuantEcon ICD Workshop (March 2024)\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "This lecture provides a short introduction to [Google JAX](https://github.com/google/jax).\n",
    "\n",
    "What GPUs do we have access to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f683b969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 26 07:26:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A2000 8GB Lap...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P0               9W /  35W |     12MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1853      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      3054      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf1331d",
   "metadata": {},
   "source": [
    "## JAX as a NumPy Replacement\n",
    "\n",
    "\n",
    "One way to use JAX is as a plug-in NumPy replacement. Let's look at the\n",
    "similarities and differences.\n",
    "\n",
    "### Similarities\n",
    "\n",
    "\n",
    "The following import is standard, replacing `import numpy as np`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d15471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef0e31",
   "metadata": {},
   "source": [
    "Now we can use `jnp` in place of `np` for the usual array operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ea4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jnp.asarray((1.0, 3.2, -1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4bcfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   3.2 -1.5]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5d21d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6999998\n"
     ]
    }
   ],
   "source": [
    "print(jnp.sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f3addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(jnp.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc9e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.490001\n"
     ]
    }
   ],
   "source": [
    "print(jnp.dot(a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d20049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.490001\n"
     ]
    }
   ],
   "source": [
    "print(a @ a)  # Equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9549ed4",
   "metadata": {},
   "source": [
    "However, the array object `a` is not a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a9bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 1. ,  3.2, -1.5], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1809299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.ArrayImpl"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0006b8",
   "metadata": {},
   "source": [
    "Even scalar-valued maps on arrays return JAX arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a55ea67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.6999998, dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf77b6",
   "metadata": {},
   "source": [
    "JAX arrays are also called \"device arrays,\" where term \"device\" refers to a\n",
    "hardware accelerator (GPU or TPU).\n",
    "\n",
    "(In the terminology of GPUs, the \"host\" is the machine that launches GPU operations, while the \"device\" is the GPU itself.)\n",
    "\n",
    "\n",
    "\n",
    "Operations on higher dimensional arrays are also similar to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0874e604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = jnp.ones((2, 2))\n",
    "B = jnp.identity(2)\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ff1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.numpy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "058b46c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.inv(B)   # Inverse of identity is identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda122fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.99999994, 0.99999994], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = linalg.eigh(B)  # Computes eigenvalues and eigenvectors\n",
    "result.eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0841a631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3968b74",
   "metadata": {},
   "source": [
    "### Differences\n",
    "\n",
    "\n",
    "One difference between NumPy and JAX is that JAX currently uses 32 bit floats by default.  \n",
    "\n",
    "This is standard for GPU computing and can lead to significant speed gains with small loss of precision.\n",
    "\n",
    "However, for some calculations precision matters.  In these cases 64 bit floats can be enforced via the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426f66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e162e",
   "metadata": {},
   "source": [
    "Let's check this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cfb2177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1., 1., 1.], dtype=float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.ones(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a76536",
   "metadata": {},
   "source": [
    "As a NumPy replacement, a more significant difference is that arrays are treated as **immutable**.  \n",
    "\n",
    "For example, with NumPy we can write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b302f6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.linspace(0, 1, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc062ce2",
   "metadata": {},
   "source": [
    "and then mutate the data in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7e4365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.5, 1. ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb19043",
   "metadata": {},
   "source": [
    "In JAX this fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "369c5d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0. , 0.5, 1. ], dtype=float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = jnp.linspace(0, 1, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed1673b2",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:278\u001b[0m, in \u001b[0;36m_unimplemented_setitem\u001b[0;34m(self, i, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unimplemented_setitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, i, x):\n\u001b[1;32m    274\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object does not support item assignment. JAX arrays are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimmutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor another .at[] method: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html"
     ]
    }
   ],
   "source": [
    "a[0] = 1   # uncommenting produces a TypeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80f7d2",
   "metadata": {},
   "source": [
    "The designers of JAX chose to make arrays immutable because JAX uses a\n",
    "functional programming style.  More on this below.  \n",
    "\n",
    "Note that, while mutation is discouraged, it is in fact possible with `at`, as in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e80c371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116622752"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = jnp.linspace(0, 1, 3)\n",
    "id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "231e9d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0. , 0.5, 1. ], dtype=float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "747f4e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1. , 0.5, 1. ], dtype=float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.at[0].set(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7f32a",
   "metadata": {},
   "source": [
    "We can check that the array is mutated by verifying its identity is unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "011c3c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116622752"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f48135",
   "metadata": {},
   "source": [
    "## Random Numbers\n",
    "\n",
    "Random numbers are also a bit different in JAX, relative to NumPy.  \n",
    "\n",
    "Typically, in JAX, the state of the random number generator needs to be controlled explicitly.\n",
    "\n",
    "(This is also related to JAX's functional programming paradigm, discussed below.  JAX does not typically work with objects that maintain state, such as the state of a random number generator.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4843678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.random as random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d9c1c",
   "metadata": {},
   "source": [
    "First we produce a key, which seeds the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d91f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed6d8a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.ArrayImpl"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d61a2e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5867580",
   "metadata": {},
   "source": [
    "Now we can use the key to generate some random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e5f050c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-1.35247421, -0.2712502 , -0.02920518],\n",
       "       [ 0.34706456,  0.5464053 , -1.52325812],\n",
       "       [ 0.41677264, -0.59710138, -0.5678208 ]], dtype=float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random.normal(key, (3, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17bbe0",
   "metadata": {},
   "source": [
    "If we use the same key again, we initialize at the same seed, so the random numbers are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b526e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-1.35247421, -0.2712502 , -0.02920518],\n",
       "       [ 0.34706456,  0.5464053 , -1.52325812],\n",
       "       [ 0.41677264, -0.59710138, -0.5678208 ]], dtype=float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.normal(key, (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d205fe6",
   "metadata": {},
   "source": [
    "To produce a (quasi-) independent draw, best practice is to \"split\" the existing key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d4f14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f15a4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.85374374, -0.37683949, -0.61276867],\n",
       "       [-1.91829718,  0.27219409,  0.54922246],\n",
       "       [ 0.40451442, -0.58726839, -0.63967753]], dtype=float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.normal(key, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e1010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.4300635 ,  0.22778552,  0.57241269],\n",
       "       [-0.15969178,  0.46719192,  0.21165091],\n",
       "       [ 0.84118631,  1.18671326, -0.16607783]], dtype=float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.normal(subkey, (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0a1c3",
   "metadata": {},
   "source": [
    "The function below produces `k` (quasi-) independent random `n x n` matrices using this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed719c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_matrices(key, n, k):\n",
    "    matrices = []\n",
    "    for _ in range(k):\n",
    "        key, subkey = random.split(key)\n",
    "        matrices.append(random.uniform(subkey, (n, n)))\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "986531ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97440813 0.3838544 ]\n",
      " [0.9790686  0.99981046]]\n",
      "[[0.3473302  0.17157842]\n",
      " [0.89346686 0.01403153]]\n"
     ]
    }
   ],
   "source": [
    "matrices = gen_random_matrices(key, 2, 2)\n",
    "for A in matrices:\n",
    "    print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050204d",
   "metadata": {},
   "source": [
    "One point to remember is that JAX expects tuples to describe array shapes, even for flat arrays.  Hence, to get a one-dimensional array of normal random draws we use `(len, )` for the shape, as in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1016a4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.64377279,  0.76961857, -0.29809604,  0.47858776, -2.00591299],      dtype=float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.normal(key, (5,))   # not random.normal(key, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a196645",
   "metadata": {},
   "source": [
    "## JIT compilation\n",
    "\n",
    "The JAX just-in-time (JIT) compiler accelerates logic within functions by fusing linear\n",
    "algebra operations into a single optimized kernel that the host can\n",
    "launch on the GPU / TPU (or CPU if no accelerator is detected).\n",
    "\n",
    "### A first example\n",
    "\n",
    "To see the JIT compiler in action, consider the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52f3641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n",
    "    return jnp.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b14c39",
   "metadata": {},
   "source": [
    "Let's build an array to call the function on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1913823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50_000_000\n",
    "x = jnp.ones(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c52e9a",
   "metadata": {},
   "source": [
    "How long does the function take to execute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "704e98b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 340 ms, sys: 10.9 ms, total: 351 ms\n",
      "Wall time: 804 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(2.19896006e+08, dtype=float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072ea85",
   "metadata": {},
   "source": [
    "(In order to measure actual speed, we use `block_until_ready()` method \n",
    "to hold the interpreter until the results of the computation are returned from\n",
    "the device. This is necessary because JAX uses asynchronous dispatch, which\n",
    "allows the Python interpreter to run ahead of GPU computations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f485852",
   "metadata": {},
   "source": [
    "The code doesn't run as fast as we might hope, given that it's running on a GPU.\n",
    "\n",
    "But if we run it a second time it becomes much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1f300c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.86 ms, sys: 3.56 ms, total: 8.42 ms\n",
      "Wall time: 184 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(2.19896006e+08, dtype=float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "219df678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 ms ± 105 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe7240",
   "metadata": {},
   "source": [
    "This is because the built in functions like `jnp.cos` are JIT compiled and the\n",
    "first run includes compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc9c6e",
   "metadata": {},
   "source": [
    "### When does JAX recompile?\n",
    "\n",
    "You might remember that Numba recompiles if we change the types of variables in a function call.\n",
    "\n",
    "JAX recompiles more often --- in particular, it recompiles every time we change array sizes.\n",
    "\n",
    "For example, let's try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2506239",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = n + 1\n",
    "y = jnp.ones(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4a38da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 276 ms, sys: 26.1 ms, total: 303 ms\n",
      "Wall time: 788 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(2.19896011e+08, dtype=float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f(y).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a7b59",
   "metadata": {},
   "source": [
    "Notice that the execution time increases, because now new versions of \n",
    "the built-ins like `jnp.cos` are being compiled, specialized to the new array\n",
    "size.\n",
    "\n",
    "If we run again, the code is dispatched to the correct compiled version and we\n",
    "get faster execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffe30181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.6 ms, sys: 0 ns, total: 7.6 ms\n",
      "Wall time: 182 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(2.19896011e+08, dtype=float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f(y).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f30470",
   "metadata": {},
   "source": [
    "Why does JAX generate fresh machine code every time we change the array size???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde9ad75",
   "metadata": {},
   "source": [
    "The compiled versions for the previous array size are still available in memory\n",
    "too, and the following call is dispatched to the correct compiled code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76a0b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 707 µs, sys: 7.58 ms, total: 8.29 ms\n",
      "Wall time: 185 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(2.19896006e+08, dtype=float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8cf3b",
   "metadata": {},
   "source": [
    "### Compiling user-built functions\n",
    "\n",
    "We can instruct JAX to compile entire functions that we build.\n",
    "\n",
    "For example, consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7872b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    y = jnp.zeros_like(x)\n",
    "    for i in range(10):\n",
    "        y += x**i\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a7185bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000_000\n",
    "x = jnp.ones(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ff410",
   "metadata": {},
   "source": [
    "Let's time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3b19b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 306 ms, sys: 5.14 ms, total: 311 ms\n",
      "Wall time: 766 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([10., 10., 10., ..., 10., 10., 10.], dtype=float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47c0c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 ms, sys: 309 µs, total: 6.58 ms\n",
      "Wall time: 4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([10., 10., 10., ..., 10., 10., 10.], dtype=float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05121c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_jit = jax.jit(g)   # target for JIT compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523f891",
   "metadata": {},
   "source": [
    "Let's run once to compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "945f3c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([10., 10., 10., ..., 10., 10., 10.], dtype=float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71370d32",
   "metadata": {},
   "source": [
    "And now let's time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebb0d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.88 ms, total: 1.88 ms\n",
      "Wall time: 1.06 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([10., 10., 10., ..., 10., 10., 10.], dtype=float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time g_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d78d4d",
   "metadata": {},
   "source": [
    "Note the speed gain.\n",
    "\n",
    "This is because \n",
    "\n",
    "1. the loop is compiled and\n",
    "2. the array operations are fused and no intermediate arrays are created.\n",
    "\n",
    "\n",
    "Incidentally, a more common syntax when targetting a function for the JIT\n",
    "compiler is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54ad0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def g_jit_2(x):\n",
    "    y = jnp.zeros_like(x)\n",
    "    for i in range(10):\n",
    "        y += x**i\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1a579aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.8 ms, sys: 5.55 ms, total: 92.3 ms\n",
      "Wall time: 77.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([10., 10., 10., ..., 10., 10., 10.], dtype=float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time g_jit_2(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c23e3d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 ms, sys: 155 µs, total: 1.25 ms\n",
      "Wall time: 965 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([10., 10., 10., ..., 10., 10., 10.], dtype=float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time g_jit_2(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e9f60",
   "metadata": {},
   "source": [
    "## Functional Programming\n",
    "\n",
    "From JAX's documentation:\n",
    "\n",
    "*When walking about the countryside of Italy, the people will not hesitate to tell you that JAX has “una anima di pura programmazione funzionale”.*\n",
    "\n",
    "\n",
    "In other words, JAX assumes a functional programming style.\n",
    "\n",
    "The major implication is that JAX functions should be pure.\n",
    "    \n",
    "A pure function will always return the same result if invoked with the same inputs.\n",
    "\n",
    "In particular, a pure function has\n",
    "\n",
    "* no dependence on global variables and\n",
    "* no side effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fafc002",
   "metadata": {},
   "source": [
    "### Example: Python/NumPy/Numba style code is not pure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aae997",
   "metadata": {},
   "source": [
    "Here's an example to show that NumPy functions are not pure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c8bb0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3359665502216457"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "490665be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.578972263482247"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841f7c2",
   "metadata": {},
   "source": [
    "This fails the test: a function returns the same result when called on the same inputs.\n",
    "\n",
    "The issue is that the function maintains internal state between function calls --- the state of the random number generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845033bc",
   "metadata": {},
   "source": [
    "Here's a function that fails to be pure because it modifies external state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8376edca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def double_input(x):   # Not pure -- side effects\n",
    "    x[:] = 2 * x\n",
    "    return None\n",
    "\n",
    "x = np.ones(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8b954bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_input(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef428898",
   "metadata": {},
   "source": [
    "Here's a pure version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8de56bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_input(x):\n",
    "    y = 2 * x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027d731",
   "metadata": {},
   "source": [
    "The following function is also not pure, since it modifies a global variable (similar to the last example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dca5e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "def f():\n",
    "    global a\n",
    "    a += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a6682e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2102ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3192e390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b81ec0",
   "metadata": {},
   "source": [
    "### Compiling impure functions\n",
    "\n",
    "JAX does not insist on pure functions.\n",
    "\n",
    "For example, JAX will not usually throw errors when compiling impure functions \n",
    "\n",
    "However, execution becomes unpredictable!\n",
    "\n",
    "Here's an illustration of this fact, using global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bdf89965",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1  # global\n",
    "\n",
    "@jax.jit\n",
    "def f(x):\n",
    "    return a + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3c3ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e636ac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1., 1.], dtype=float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a51e1d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([2., 2.], dtype=float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67418cfa",
   "metadata": {},
   "source": [
    "In the code above, the global value `a=1` is fused into the jitted function.\n",
    "\n",
    "Even if we change `a`, the output of `f` will not be affected --- as long as the same compiled version is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b6b770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c9c55cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([2., 2.], dtype=float64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc43691",
   "metadata": {},
   "source": [
    "Notice that the change in the value of `a` takes effect in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b02fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "417e9746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([43., 43., 43.], dtype=float64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5966a47",
   "metadata": {},
   "source": [
    "Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaea151",
   "metadata": {},
   "source": [
    "Moral of the story: write pure functions when using JAX!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95fac8",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "\n",
    "JAX can use automatic differentiation to compute gradients.\n",
    "\n",
    "This can be extremely useful for optimization and solving nonlinear systems.\n",
    "\n",
    "We will see significant applications later in this lecture series.\n",
    "\n",
    "For now, here's a very simple illustration involving the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "20e91784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x**2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df056899",
   "metadata": {},
   "source": [
    "Let's take the derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d3ca15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_prime = jax.grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b766913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(10., dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_prime(10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f984c9",
   "metadata": {},
   "source": [
    "Let's plot the function and derivative, noting that $f'(x) = x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06e20f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x_grid = jnp.linspace(-4, 4, 200)\n",
    "ax.plot(x_grid, f(x_grid), label=\"$f$\")\n",
    "ax.plot(x_grid, [f_prime(x) for x in x_grid], label=\"$f'$\")\n",
    "ax.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56151e",
   "metadata": {},
   "source": [
    "## Writing vectorized code\n",
    "\n",
    "Writing fast JAX code requires shifting repetitive tasks from loops to array processing operations, so that the JAX compiler can easily understand the whole operation and generate more efficient machine code.\n",
    "\n",
    "This procedure is called **vectorization** or **array programming**, and will be familiar to anyone who has used NumPy or MATLAB.\n",
    "\n",
    "In some ways, vectorization is the same in JAX as it is in NumPy.\n",
    "\n",
    "But there are also major differences, which we highlight here.\n",
    "\n",
    "As a running example, consider the function\n",
    "\n",
    "$$\n",
    "    f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}\n",
    "$$\n",
    "\n",
    "Suppose that we want to evaluate this function on a square grid of $x$ and $y$ points.\n",
    "\n",
    "\n",
    "### A slow version with loops\n",
    "\n",
    "To clarify, here is the slow `for` loop version, which we run in a setting where `len(x) = len(y)` is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5661b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def f(x, y):\n",
    "    return jnp.cos(x**2 + y**2) / (1 + x**2 + y**2)\n",
    "\n",
    "n = 80\n",
    "x = jnp.linspace(-2, 2, n)\n",
    "y = x\n",
    "\n",
    "z_loops = np.empty((n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ef7f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 s, sys: 1.26 s, total: 5.34 s\n",
      "Wall time: 3.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        z_loops[i, j] = f(x[i], y[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513cb739",
   "metadata": {},
   "source": [
    "Even for this very small grid, the run time is extremely slow.\n",
    "\n",
    "(Notice that we used a NumPy array for `z_loops` because we wanted to write to it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0345820",
   "metadata": {},
   "source": [
    "OK, so how can we do the same operation in vectorized form?\n",
    "\n",
    "If you are new to vectorization, you might guess that we can simply write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "27a1687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_bad = f(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6c3bc",
   "metadata": {},
   "source": [
    "But this gives us the wrong result because JAX doesn't understand the nested for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8c75785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_bad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9954d8",
   "metadata": {},
   "source": [
    "Here is what we actually wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c877288f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_loops.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e56ed",
   "metadata": {},
   "source": [
    "### Vectorization attempt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd06014",
   "metadata": {},
   "source": [
    "To get the right shape and the correct nested for loop calculation, we can use a `meshgrid` operation that originated in MATLAB and was replicated in NumPy and then JAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d3f26b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mesh, y_mesh = jnp.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc6ad5",
   "metadata": {},
   "source": [
    "Now we get what we want and the execution time is very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9aae02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mesh = f(x_mesh, y_mesh) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31473921",
   "metadata": {},
   "source": [
    "Let's confirm that we got the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "99419a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(z_mesh, z_loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3f00a",
   "metadata": {},
   "source": [
    "Now we can set up a serious grid and run the same calculation (on the larger grid) in a short amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e481ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6000\n",
    "x = jnp.linspace(-2, 2, n)\n",
    "y = x\n",
    "x_mesh, y_mesh = jnp.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fbd6cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.4 ms, sys: 198 µs, total: 62.6 ms\n",
      "Wall time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z_mesh = f(x_mesh, y_mesh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3dc3d39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99 µs, sys: 19 µs, total: 118 µs\n",
      "Wall time: 125 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z_mesh = f(x_mesh, y_mesh) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0117c",
   "metadata": {},
   "source": [
    "But there is one problem here: the mesh grids use a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf1391f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_mesh.nbytes + y_mesh.nbytes) / 1_000_000  # MB of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3397a6a",
   "metadata": {},
   "source": [
    "By comparison, the flat array `x` is just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7dd67b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.nbytes / 1_000_000   # and y is just a pointer to x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc373fdc-91ef-49ee-a099-7580a1090251",
   "metadata": {},
   "source": [
    "This extra memory usage can be a big problem in actual research calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ada594cf-a25c-45ac-a2ba-1294ce645433",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_mesh  # Free memory\n",
    "del y_mesh  # Free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f983f9d-876f-48cd-9a01-60f5a024d546",
   "metadata": {},
   "source": [
    "### Vectorization attempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36d04e",
   "metadata": {},
   "source": [
    "We can achieve a similar effect through NumPy style broadcasting rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4342c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = jnp.reshape(x, (n, 1))   # Give x another dimension (column)\n",
    "y_reshaped = jnp.reshape(y, (1, n))   # Give y another dimension (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d96848",
   "metadata": {},
   "source": [
    "When we evaluate $f$ on these reshaped arrays, we replicate the nested for loops in the original version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34b197a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.8 ms, sys: 84 µs, total: 61.9 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%time z_reshaped = f(x_reshaped, y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27efffa0-4f25-4228-9140-620dc36aeb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 489 µs, sys: 93 µs, total: 582 µs\n",
      "Wall time: 440 µs\n"
     ]
    }
   ],
   "source": [
    "%time z_reshaped = f(x_reshaped, y_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d8ffa",
   "metadata": {},
   "source": [
    "Let's check that we got the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c989b5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(z_reshaped, z_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f591f",
   "metadata": {},
   "source": [
    "The memory usage for the inputs is much more moderate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d83efbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.096"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_reshaped.nbytes + y_reshaped.nbytes) / 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e3f7b",
   "metadata": {},
   "source": [
    "### Vectorization attempt 3\n",
    "\n",
    "\n",
    "There's another approach to vectorization we can pursue, using [jax.vmap](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611afd3",
   "metadata": {},
   "source": [
    "It runs out that, when we are working with complex functions and operations, this `vmap` approach can be the easiest to implement.\n",
    "\n",
    "It's also very memory parsimonious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca3ccb",
   "metadata": {},
   "source": [
    "The first step is to vectorize the function `f` in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0537a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vec_y = jax.vmap(f, in_axes=(None, 0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ac181",
   "metadata": {},
   "source": [
    "In the line above, `(None, 0)` indicates that we are vectorizing in the second argument, which is `y`.\n",
    "\n",
    "Next, we vectorize in the first argument, which is `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "899bd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vec = jax.vmap(f_vec_y, in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ebc8d",
   "metadata": {},
   "source": [
    "Finally, we JIT-compile the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6eb681b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vec = jax.jit(f_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13580964",
   "metadata": {},
   "source": [
    "With this construction, we can now call the function $f$ on flat (low memory) arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "643776dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.1 ms, sys: 4.34 ms, total: 73.4 ms\n",
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z_vmap = f_vec(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "244a9add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 322 µs, sys: 0 ns, total: 322 µs\n",
      "Wall time: 317 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z_vmap = f_vec(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fb756",
   "metadata": {},
   "source": [
    "Let's check we produce the correct answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9dd4540d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(z_vmap, z_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693e277-e616-42fb-9fc4-19589b44d103",
   "metadata": {},
   "source": [
    "Let's finish by cleaning up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7aa14c55-4aea-41d2-95fe-6c7f23362351",
   "metadata": {},
   "outputs": [],
   "source": [
    "del z_mesh\n",
    "del z_vmap\n",
    "del z_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124d0f8-d0e8-4950-9efe-3b96fff50552",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f132a",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "In a previous notebook we used Monte Carlo to price a European call option and\n",
    "constructed a solution using Numba.\n",
    "\n",
    "The code looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb6e269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numpy.random import randn\n",
    "M = 10_000_000\n",
    "\n",
    "n, β, K = 20, 0.99, 100\n",
    "μ, ρ, ν, S0, h0 = 0.0001, 0.1, 0.001, 10, 0\n",
    "\n",
    "@numba.jit(parallel=True)\n",
    "def compute_call_price_parallel(β=β,\n",
    "                                μ=μ,\n",
    "                                S0=S0,\n",
    "                                h0=h0,\n",
    "                                K=K,\n",
    "                                n=n,\n",
    "                                ρ=ρ,\n",
    "                                ν=ν,\n",
    "                                M=M):\n",
    "    current_sum = 0.0\n",
    "    # For each sample path\n",
    "    for m in numba.prange(M):\n",
    "        s = np.log(S0)\n",
    "        h = h0\n",
    "        # Simulate forward in time\n",
    "        for t in range(n):\n",
    "            s = s + μ + np.exp(h) * randn()\n",
    "            h = ρ * h + ν * randn()\n",
    "        # And add the value max{S_n - K, 0} to current_sum\n",
    "        current_sum += np.maximum(np.exp(s) - K, 0)\n",
    "        \n",
    "    return β**n * current_sum / M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ecfe6",
   "metadata": {},
   "source": [
    "Let's run it once to compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f761224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171409.68191599599"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_call_price_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b0a53",
   "metadata": {},
   "source": [
    "And now let's time it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "625d5bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 0 ns, total: 19.8 s\n",
      "Wall time: 1.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141062.5730043863"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "compute_call_price_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01634ace",
   "metadata": {},
   "source": [
    "Try writing a version of this operation for JAX, using all the same\n",
    "parameters.\n",
    "\n",
    "If you are running your code on a GPU, you should be able to achieve\n",
    "significantly faster execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "07b893f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n",
      "Solution below.\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print(\"Solution below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3b2ed",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Here is one solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5158614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10_000_000\n",
    "\n",
    "n, β, K = 20, 0.99, 100\n",
    "μ, ρ, ν, S0, h0 = 0.0001, 0.1, 0.001, 10, 0\n",
    "\n",
    "@jax.jit\n",
    "def compute_call_price_jax(β=β,\n",
    "                           μ=μ,\n",
    "                           S0=S0,\n",
    "                           h0=h0,\n",
    "                           K=K,\n",
    "                           n=n,\n",
    "                           ρ=ρ,\n",
    "                           ν=ν,\n",
    "                           M=M,\n",
    "                           key=jax.random.PRNGKey(1)):\n",
    "\n",
    "    s = jnp.full(M, np.log(S0))\n",
    "    h = jnp.full(M, h0)\n",
    "    for t in range(n):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        Z = jax.random.normal(subkey, (2, M))\n",
    "        s = s + μ + jnp.exp(h) * Z[0, :]\n",
    "        h = ρ * h + ν * Z[1, :]\n",
    "    expectation = jnp.mean(jnp.maximum(jnp.exp(s) - K, 0))\n",
    "        \n",
    "    return β**n * expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c1532",
   "metadata": {},
   "source": [
    "Let's run it once to compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "050ba11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 07:27:34.807821: W external/xla/xla/service/hlo_rematerialization.cc:2941] Can't reduce memory use below 5.55GiB (5959139320 bytes) by rematerialization; only reduced to 6.33GiB (6799998824 bytes), down from 6.56GiB (7040000024 bytes) originally\n",
      "2024-03-26 07:27:47.390213: W external/tsl/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.33GiB (rounded to 6800013056)requested by op \n",
      "2024-03-26 07:27:47.390405: W external/tsl/tsl/framework/bfc_allocator.cc:494] *_____*_____**_____*________________________________________________________________________________\n",
      "E0326 07:27:47.391720  408251 pjrt_stream_executor_client.cc:2804] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6800012832 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:         0B\n",
      "              constant allocation:         0B\n",
      "        maybe_live_out allocation:         8B\n",
      "     preallocated temp allocation:    6.33GiB\n",
      "  preallocated temp fragmentation:         0B (0.00%)\n",
      "                 total allocation:    6.33GiB\n",
      "              total fragmentation:    12.5KiB (0.00%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[20000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[20000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[20000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 152.59MiB\n",
      "\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[2,10000000]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6800012832 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:         0B\n              constant allocation:         0B\n        maybe_live_out allocation:         8B\n     preallocated temp allocation:    6.33GiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    6.33GiB\n              total fragmentation:    12.5KiB (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[20000000]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[20000000]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[20000000]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compute_call_price_jax()\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1209\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxla_executable\u001b[38;5;241m.\u001b[39mexecute_sharded(input_bufs)\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1211\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 6800012832 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:         0B\n              constant allocation:         0B\n        maybe_live_out allocation:         8B\n     preallocated temp allocation:    6.33GiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    6.33GiB\n              total fragmentation:    12.5KiB (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[20000000]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[20000000]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[20000000]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 152.59MiB\n\t\tOperator: op_name=\"jit(compute_call_price_jax)/jit(main)/jit(_normal)/jit(_normal_real)/erf_inv\" source_file=\"/tmp/ipykernel_408251/3762069436.py\" source_line=22\n\t\tXLA Label: fusion\n\t\tShape: f64[2,10000000]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "compute_call_price_jax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e74a57",
   "metadata": {},
   "source": [
    "And now let's time it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec461bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "compute_call_price_jax().block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5edaeac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
